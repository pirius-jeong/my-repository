# 4장. Reflection(반사) 패턴

## 4.1 반사 패턴 개요

- **정의**: 에이전트가 자신의 출력·계획·상태를 **평가하고, 그 결과를 반영해 다시 개선**하는 자기 교정(self-correction) 패턴이다.
- 체이닝·라우팅·병렬화만으로는 “한 번 생성된 출력”이 그대로 확정되기 때문에, 품질·정확성·완전성에 한계가 있다.
- Reflection은 **피드백 루프**를 도입해, 생성 → 평가 → 개선 → (반복) 구조를 만든다.

### 기본 흐름

1. 실행: 초기 출력/계획 생성.  
2. 평가·비평: 별도 LLM 호출·규칙·도구로 출력 품질을 점검.  
3. 반성·개선: 비평 내용을 근거로 수정·재작성·전략 조정.  
4. 반복: 만족 기준 또는 반복 한도까지 루프.

---

## 4.2 Producer–Critic(생성자–비평가) 모델

- 효과적인 구현 방식: **역할을 분리**해 두 에이전트로 설계.

### 1) Producer(프로듀서) 에이전트

- 역할: 초안·초기 코드·초기 계획 등 **1차 산출물 생성**에 집중.
- 입력: 사용자 프롬프트·요구사항.
- 출력: 첫 버전 결과물.

### 2) Critic(비평가) 에이전트

- 역할: Producer 결과를 **전문가 관점에서 평가·비판**.
- 페르소나 예시:  
  - “선임 소프트웨어 엔지니어” (코드 품질·버그·예외 처리 체크)  
  - “꼼꼼한 팩트체커” (사실 검증·출처·논리성 체크)
- 작업: 결함 찾기, 누락·불일치 지적, 개선 방향 제안.

### 3) 루프 구조

- Producer 출력 → Critic 비평 → Producer가 비평을 반영해 재작성 → 반복.
- 장점:  
  - 자기 편향(Self-bias) 감소, 새로운 시각에서 검토.  
  - 고품질·고신뢰 결과를 위한 구조화된 피드백 루프.

---

## 4.3 Reflection이 특히 유용한 작업 유형

### 4.3.1 창의적 글쓰기·콘텐츠 생성

- 예: 블로그 글, 스토리, 마케팅 카피.
- 흐름: 초안 작성 → 흐름·톤·명확성·설득력 검토 → 재작성 → 품질 기준 충족까지 반복.
- 효과: 더 세련되고 목적에 맞는 콘텐츠.

### 4.3.2 코드 생성·디버깅

- 예: Python 함수 작성 에이전트.
- 흐름:  
  - 초기 코드 생성 → 테스트/정적 분석/코드 리뷰 프롬프트 → 버그·비효율 탐지 → 수정.
- 효과: 더 견고하고 예외 처리까지 포함된 코드.

### 4.3.3 복잡한 문제 해결·추론

- 예: 논리 퍼즐, 수학 문제, 다단계 추론.
- 흐름:  
  - 풀이 단계 제안 → 모순·비일관성 여부 검토 → 잘못된 단계 롤백/수정 → 대안 경로 탐색.
- 효과: 복잡한 문제 공간을 더 안정적으로 탐색.

### 4.3.4 요약·정보 합성

- 예: 긴 문서 요약 에이전트.
- 흐름:  
  - 1차 요약 생성 → 원본과 비교해 누락·오류·왜곡 점검 → 수정 요약 생성.
- 효과: 더 정확·포괄·간결한 요약.

### 4.3.5 계획·전략 수립

- 예: 프로젝트 플랜, 학습 계획, 비즈니스 전략.
- 흐름: 계획 작성 → 제약·실행 가능성·리스크 평가 → 시뮬레이션·보완 → 수정.
- 효과: 현실적이고 리스크를 고려한 계획.

### 4.3.6 대화형 에이전트

- 예: 고객지원 챗봇.
- 흐름: 응답 생성 후 대화 히스토리·사용자 최신 입력과 **자체 응답**을 검토 → 오해·톤 문제·누락정보 감지 → 수정 응답.
- 효과: 더 자연스럽고 일관된 대화 경험.

---

## 4.4 구현 관점: LangChain·LangGraph·ADK

### 4.4.1 LangChain / LCEL 예시

- 구조:  
  - 작업 프롬프트 → 코드 생성 → “선임 엔지니어” 역할 프롬프트로 코드 비평 →  
    - 비평이 `CODE_IS_PERFECT`이면 종료,  
    - 아니면 비평을 히스토리에 추가하고 “비평을 반영해 코드를 개선하라” 프롬프트로 재생성.
- 구현 포인트:  
  - 대화 히스토리를 누적하며, 각 루프에서 이전 코드·비평을 함께 제공.  
  - 최대 반복 수, `CODE_IS_PERFECT` 같은 정지 조건을 명시.

### 4.4.2 Google ADK 예시

- Generator LlmAgent:  
  - 주제에 대한 짧은 정보성 문단 생성, `draft_text` 상태 키에 저장.
- Reviewer LlmAgent:  
  - `draft_text`를 읽고 사실 정확성을 검토,  
  - `status`(ACCURATE/INACCURATE) + `reasoning`이 담긴 dict를 `review_output`에 저장.
- SequentialAgent 파이프라인:  
  - Generator → Reviewer 순으로 실행을 보장, 생성-검토 파이프라인 구성.

---

## 4.5 Reflection + 메모리·목표 관리

- 목표 설정·모니터링과의 관계:  
  - 목표는 “무엇이 좋은 결과인가?”에 대한 평가 기준을 제공.  
  - 모니터링은 진행 상황·편차를 추적.  
  - Reflection은 이 피드백을 활용해 전략·출력을 교정하는 “교정 엔진” 역할.
- 메모리와의 결합:  
  - 대화 이력·사용자 피드백·과거 오류를 기억하면,  
    - 매번 독립적으로 평가하는 것이 아니라, **이전 비판을 학습**해 반복 오류를 줄일 수 있다.  
  - 기억이 없으면 각 Reflection이 독립 사건, 기억이 있으면 누적적 학습 과정.

---

## 4.6 비용·제약과 트레이드오프

- 장점:  
  - 품질·정확도·가이드라인 준수 큰 폭 향상.  
  - 세밀한 작업(코드, 장문, 계획 등)에 매우 유효.
- 단점:  
  - 반복마다 LLM 호출 → 비용·지연 시간 증가.  
  - 대화 히스토리가 길어져 컨텍스트 창 한계·서비스 제한에 더 빨리 도달.  
  - 전체 오케스트레이션·상태 관리 복잡도 증가.
- 설계 기준:  
  - “속도·비용 < 결과물 품질·정확성”인 경우에 Reflection을 적용.  
  - 모든 작업에 일괄 적용하기보다, **고위험·고가치 출력**에 선택적으로 쓰는 것이 실용적.

---

## 4.7 한눈에 보기

- **무엇**: 에이전트가 자신의 출력을 평가·비판·개선하는 **자기 반성 피드백 루프**.
- **왜**: 초기 LLM 출력은 종종 부정확·불완전·지침 위반이므로, 최종 결과로 그대로 쓰기엔 위험하다.
- **어떻게**:  
  - Producer–Critic 역할 분리,  
  - 생성–평가–개선 루프,  
  - LangChain·LangGraph·ADK 등으로 상태·반복 제어.
- **언제**: 코드, 장문 콘텐츠, 계획, 고정확도 요구 작업 등에서 **속도보다 품질이 중요할 때**.

---

## 4.8 핵심 정리

- Reflection 패턴은 “한 번 생성하고 끝나는 에이전트”를 넘어, **스스로를 수정·개선하는 에이전트**를 만드는 핵심 메커니즘이다.
- 다른 기본 패턴(체이닝·라우팅·병렬화)과 결합하면, 고품질·고난도 작업에 대응 가능한 정교한 에이전트 아키텍처를 설계할 수 있다.
